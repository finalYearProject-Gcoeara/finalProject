{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f481b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\engra\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\engra\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\engra\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\engra\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\engra\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\engra\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\engra\\anaconda3\\lib\\site-packages (from requests) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58661faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Example Flipkart URL (this URL should be updated to the specific product you're targeting)\n",
    "# url = \"https://www.flipkart.com/samsung-galaxy-s23-fe-mint-256-gb/p/itmdb72279972171?pid=MOBGVTA2R8ZH4G3C&lid=LSTMOBGVTA2R8ZH4G3C8XDOZH&marketplace=FLIPKART&store=tyy%2F4io&spotlightTagId=FkPickId_tyy%2F4io&srno=b_1_3&otracker=CLP_BannerX3&fm=organic&iid=03af5775-4df1-4aae-b702-3239b07440f8.MOBGVTA2R8ZH4G3C.SEARCH&ppt=browse&ppn=browse&ssid=fa73z3qh9c0000001729063210433\"\n",
    "url = \"https://www.flipkart.com/oppo-k12x-5g-45w-supervooc-charger-in-the-box-midnight-voilet-128-gb/p/itma30cb38861d4c?pid=MOBH2Q4PGYYZDSRR&lid=LSTMOBH2Q4PGYYZDSRRJXREQR&marketplace=FLIPKART&store=tyy%2F4io&spotlightTagId=BestsellerId_tyy%2F4io&srno=b_1_2&otracker=clp_banner_2_7.bannerX3.BANNER_mobile-phones-store_0VYGFVGYKZPF&fm=neo%2Fmerchandising&iid=2a834dcf-ed32-4b73-8dd1-4602bf308b85.MOBH2Q4PGYYZDSRR.SEARCH&ppt=browse&ppn=browse&ssid=y33m8mhdxc0000001729066463483\"\n",
    "# Send a GET request to the URL\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Referer\": \"https://www.flipkart.com/\",\n",
    "}\n",
    "\n",
    "# print(\"Status Code:\", response.status_code)\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "# print(response)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract the product name\n",
    "    product_name = soup.find(\"span\", class_=\"VU-ZEz\").text  # Update class name as per the actual HTML structure\n",
    "    # Extract other data, like price\n",
    "    price = soup.find(\"div\", class_=\"Nx9bqj CxhGGd\").text  # Update class name as per the actual HTML structure\n",
    "\n",
    "    print(f\"Product Name: {product_name}\")\n",
    "    print(f\"Price: {price}\")\n",
    "    \n",
    "    # Initialize DataFrame\n",
    "    reviews_data = pd.DataFrame(columns=[\"rating\", \"review_title\", \"review_desc\"])\n",
    "    review_container = soup.find_all(\"div\", class_=\"col EPCmJX\")  # Update based on actual HTML structure\n",
    "\n",
    "    # Loop through each review\n",
    "    for review in review_container:\n",
    "#         print(review)\n",
    "        try:\n",
    "            # Extract rating\n",
    "#             print(\"hi\")\n",
    "            rating_div = review.find(\"div\", class_=\"row\")\n",
    "            rating_div1 = rating_div.find(\"div\", class_=\"XQDdHH Ga3i8K\")\n",
    "    \n",
    "            rating = rating_div1.text.strip() if rating_div1 else None\n",
    "            review_title = rating_div.find('p', class_=\"z9E0IG\").text.strip() if rating_div1 else None\n",
    "            print(rating)\n",
    "            print(review_title)\n",
    "\n",
    "            # Extract review title\n",
    "#             review_title = review.find(\"p\", class_=\"_2-N8zT\").text.strip()\n",
    "\n",
    "            # Extract review description\n",
    "            review_desc = review.find(\"div\", class_=\"ZmyHeo\").text.strip()\n",
    "            print(review_desc)\n",
    "\n",
    "            # Append to DataFrame\n",
    "            reviews_data = reviews_data.append({\"rating\": rating, \"review_title\": review_title, \"review_desc\": review_desc}, ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing review: {e}\")\n",
    "\n",
    "    print(f\"Total Reviews Extracted: {len(reviews_data)}\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2994c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
